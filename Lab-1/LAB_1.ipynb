{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "13ff04ff-2f03-4c1b-8f94-5c0fff5bbd24",
      "metadata": {
        "id": "13ff04ff-2f03-4c1b-8f94-5c0fff5bbd24"
      },
      "source": [
        "# Question-1\n",
        "Write a Python code to build a deep neural network using Keras and compute a number of parameters, memory and FLOPs for the following model. Use relu activations functions in the hidden layers and sigmoid activations function in the output layers.\n",
        "\n",
        "\n",
        "CPU that performs 1 GFLOPS (1,000,000,000) per seconds and computes the inference time of the Deep neural network model.\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"2.png\" width=\"700\" height=\"500\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3bbfd46-dc1d-403b-bde7-5daab5627172",
      "metadata": {
        "id": "a3bbfd46-dc1d-403b-bde7-5daab5627172"
      },
      "source": [
        "##  Parameters calculation in Deep neural network\n",
        "\n",
        "The number of internal parameters in a neural network is the total number of weights + the total number of biases. The total number of weights equals the sum of the products of each pair of adjacent layers. The total number of biases equals the number of hidden neurons + the number of output neurons.\n",
        "\n",
        "## Model Size calculations\n",
        "\n",
        "\n",
        "Model Size (in bytes)=Number of Parameters×Bytes Per Parameter\n",
        "Model Size (in KB)=Model Size (in bytes)/1024\n",
        "\n",
        "##  FLOPs calculation in Deep neural network\n",
        "FLOPs of  FC=2*(input size x output size )+(output size x activation)\n",
        "\n",
        "## Activation functions FLOPS for  Tensor Flow\n",
        "\n",
        "Relu  -->      1FLOPs\n",
        "\n",
        "Sigmoid   -->   1FLOPs\n",
        "\n",
        "Tanh   -->      1FLOPs\n",
        "\n",
        "Softmax    -->  6FLOPs\n",
        "\n",
        "## Infrences time calculations\n",
        "\n",
        "The inference time = FLOPs/FLOPS.\n",
        "\n",
        "FLOPs-> measures computational complexity of the model.\n",
        "\n",
        "FLOPS-> measures the hardware’s processing capability\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install tensorflow==2.13.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jKOPtjnMnF45",
        "outputId": "5a0bc072-4d81-4e47-d970-4b439b3e9c19"
      },
      "id": "jKOPtjnMnF45",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.13.0\n",
            "  Downloading tensorflow-2.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (25.1.21)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.13.0)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (1.69.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (3.12.1)\n",
            "Collecting keras<2.14,>=2.13.1 (from tensorflow==2.13.0)\n",
            "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (18.1.1)\n",
            "Collecting numpy<=1.24.3,>=1.22 (from tensorflow==2.13.0)\n",
            "  Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (1.17.0)\n",
            "Collecting tensorboard<2.14,>=2.13 (from tensorflow==2.13.0)\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow==2.13.0)\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (2.5.0)\n",
            "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow==2.13.0)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (1.17.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.13.0) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.27.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow==2.13.0)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.2.2)\n",
            "Downloading tensorflow-2.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.2/524.2 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: typing-extensions, tensorflow-estimator, numpy, keras, gast, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.5.0\n",
            "    Uninstalling keras-3.5.0:\n",
            "      Successfully uninstalled keras-3.5.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.1\n",
            "    Uninstalling tensorflow-2.17.1:\n",
            "      Successfully uninstalled tensorflow-2.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pymc 5.19.1 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "openai 1.59.9 requires typing-extensions<5,>=4.11, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "torch 2.5.1+cu121 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "altair 5.5.0 requires typing-extensions>=4.10.0; python_version < \"3.14\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "sqlalchemy 2.0.37 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "langchain-core 0.3.31 requires typing-extensions>=4.7, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic 2.10.5 requires typing-extensions>=4.12.2, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "blosc2 3.0.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\n",
            "typeguard 4.4.1 requires typing-extensions>=4.10.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.13.0 which is incompatible.\n",
            "nibabel 5.3.2 requires typing-extensions>=4.6; python_version < \"3.13\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "pydantic-core 2.27.2 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 keras-2.13.1 numpy-1.24.3 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 typing-extensions-4.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "keras",
                  "numpy",
                  "tensorflow"
                ]
              },
              "id": "979d0a6306e94e5c9c7002abd0515789"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "50bc661c-0608-479a-a379-ce4f7a7a1712",
      "metadata": {
        "id": "50bc661c-0608-479a-a379-ce4f7a7a1712"
      },
      "outputs": [],
      "source": [
        "### Write  your code here\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense\n",
        "\n",
        "\n",
        "model=Sequential([Dense(5,activation='relu',input_shape=(5,)),\n",
        "                  Dense(5,activation='relu'),\n",
        "                  Dense(1,activation='relu')\n",
        "                  ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0f9bba23",
      "metadata": {
        "id": "0f9bba23"
      },
      "outputs": [],
      "source": [
        "def compute(model):\n",
        "    totparm=0\n",
        "    totflops=0\n",
        "    for layer in model.layers:\n",
        "        layertype=layer.__class__.__name__\n",
        "        if layertype =='Dense':\n",
        "            inputunits=layer.input_shape[-1]\n",
        "            outputunits=layer.output_shape[-1]\n",
        "            parm = inputunits*outputunits + outputunits\n",
        "            flops = 2*inputunits*outputunits\n",
        "        totparm+=parm\n",
        "        totflops+=flops\n",
        "    return totparm,totflops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1aaa61d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aaa61d4",
        "outputId": "7c48d095-1ef5-4228-df13-8fb94899cbb3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(66, 110)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "compute(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcca70a6-efbd-4ec7-a94c-2fc83072a07b",
      "metadata": {
        "id": "dcca70a6-efbd-4ec7-a94c-2fc83072a07b"
      },
      "source": [
        "# Question-2\n",
        "Write a Python code to build a deep neural network using Keras and compute a number of parameters, memory and FLOPs for the following model. Use relu activations functions in the hidden layers and softmax activations function in the output layers. Write a Python code plot  the bar graph of the question 1 and question 2 output and compare.\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"1.png\" width=\"700\" height=\"500\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1a795d48-531a-4917-b708-dd9af3f2f2cd",
      "metadata": {
        "id": "1a795d48-531a-4917-b708-dd9af3f2f2cd"
      },
      "outputs": [],
      "source": [
        "### Write  your code here\n",
        "model=Sequential([Dense(9,activation='relu',input_shape=(4,)),\n",
        "                  Dense(6,activation='relu'),\n",
        "                  Dense(3,activation='softmax')\n",
        "                  ])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute(model):\n",
        "  totparam=0\n",
        "  totflops=0\n",
        "  acti_flops_map={\n",
        "      \"relu\": 1,\n",
        "      \"sigmoid\": 1,\n",
        "      \"tanh\": 1,\n",
        "      \"softmax\": 6,\n",
        "  }\n",
        "\n",
        "  for layer in model.layers:\n",
        "    layertype=layer.__class__.__name__\n",
        "    acti_flops=0\n",
        "    acti=getattr(layer, \"activation\" , None)\n",
        "    acti_name=acti.__name__ if acti else None\n",
        "\n",
        "    if layertype in [\"Dense\"]:\n",
        "     inputunits=layer.input_shape[-1]\n",
        "     outputunits=layer.output_shape[-1]\n",
        "     param=inputunits*outputunits+outputunits\n",
        "     flops=2*outputunits*inputunits\n",
        "     acti_flops=outputunits*acti_flops_map.get(acti_name,0)\n",
        "\n",
        "     totparam+=param\n",
        "     totflops+=flops+acti_flops\n",
        "  return totparam,totflops"
      ],
      "metadata": {
        "id": "qyORZKgisJx9"
      },
      "id": "qyORZKgisJx9",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzpoZ0G9sUSd",
        "outputId": "8ea7d995-a47a-40b6-e7e0-64809a28679e"
      },
      "id": "pzpoZ0G9sUSd",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(126, 249)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96f4995f-d746-4d7d-98eb-5cf732c02fac",
      "metadata": {
        "id": "96f4995f-d746-4d7d-98eb-5cf732c02fac"
      },
      "source": [
        "## Output Dimensions Formula for 2D Convolution\n",
        "<img src=\"10.png\" width=\"600\" height=\"400\">\n",
        "\n",
        "## Parameter calculation of 2DCNN\n",
        "\n",
        "\n",
        "<img src=\"4.png\" width=\"400\" height=\"200\">\n",
        "\n",
        "## FLOPs calculation of 2DCNN\n",
        "<img src=\"6.png\" width=\"600\" height=\"400\">\n",
        "\n",
        "\n",
        "\n",
        "## FLOPs calculation for Pooling Layers\n",
        "<img src=\"12.png\" width=\"600\" height=\"400\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bec5bed0-e48b-472c-82d8-c84fcb7bb443",
      "metadata": {
        "id": "bec5bed0-e48b-472c-82d8-c84fcb7bb443"
      },
      "source": [
        "# Question-3\n",
        "\n",
        "Write a Python code build 2DCNN model for the following specifications using Keras and compute the number of parameters ,model size and FLOPs\n",
        "\n",
        "The model architecture consists of several layers designed for image classification tasks, such as recognizing digits from the MNIST dataset. The architecture begins with a 2D convolutional layer (Conv2D), which applies 32 filters of size 3x3 to the input image (28x28x1), followed by the ReLU activation function to introduce non-linearity. This is followed by a max-pooling layer (MaxPooling2D) with a pool size of 2x2, reducing the spatial dimensions of the feature maps while retaining important information. A second convolutional layer with 64 filters of size 3x3 is then applied, again using ReLU activation. Another max-pooling layer  (2x2 ) follows to further downsample the feature maps. The output of the convolutional layers is then flattened into a one-dimensional vector using the Flatten layer, which is fed into the fully connected dense layers. The first dense layer has 64 neurons with ReLU activation, allowing the model to learn complex representations, while the final dense layer has 10 neurons with a softmax activation function, providing probabilities for each of the 10 possible digit classes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0140dc76-f695-41d3-bd81-b0627fd9950e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0140dc76-f695-41d3-bd81-b0627fd9950e",
        "outputId": "5a17ed69-6f17-4db2-fe19-085e6ded42dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                102464    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121930 (476.29 KB)\n",
            "Trainable params: 121930 (476.29 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "### Write  your code here\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_size(model):\n",
        "    param_size = 4\n",
        "    params = model.count_params()\n",
        "    size = params * param_size\n",
        "    return size"
      ],
      "metadata": {
        "id": "-3TDA72vtgjy"
      },
      "id": "-3TDA72vtgjy",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_size = get_model_size(model)\n",
        "print(f\"Model size: {model_size / (1024 ** 2):.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgkRUN4Ot753",
        "outputId": "9a88559b-7a8b-4e92-ddab-e2207807ec1e"
      },
      "id": "QgkRUN4Ot753",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model size: 0.47 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute(model):\n",
        "    totparam = 0\n",
        "    totflops = 0\n",
        "\n",
        "    acti_flops_map = {\n",
        "        \"relu\": 1,\n",
        "        \"sigmoid\": 1,\n",
        "        \"tanh\": 1,\n",
        "        \"softmax\": 6,\n",
        "    }\n",
        "\n",
        "    for layer in model.layers:\n",
        "        layertype = layer.__class__.__name__\n",
        "        acti_flops = 0\n",
        "        acti = getattr(layer, \"activation\", None)\n",
        "        acti_name = acti.__name__ if acti else None\n",
        "\n",
        "        if layertype in [\"Dense\"]:\n",
        "            inputunits = layer.input_shape[-1]\n",
        "            outputunits = layer.output_shape[-1]\n",
        "            param = inputunits * outputunits + outputunits\n",
        "            flops = 2 * outputunits * inputunits\n",
        "            acti_flops = outputunits * acti_flops_map.get(acti_name, 0)\n",
        "\n",
        "        elif layertype in [\"Conv2D\", \"Conv3D\"]:\n",
        "            kernel_size = layer.kernel_size\n",
        "            input_shape = layer.input_shape\n",
        "            output_shape = layer.output_shape\n",
        "            filters = layer.filters\n",
        "\n",
        "            param = (filters * kernel_size[0] * kernel_size[1] *\n",
        "                     input_shape[-1]) + filters\n",
        "\n",
        "            output_elements = output_shape[1] * output_shape[2] * filters\n",
        "            flops = 2 * kernel_size[0] * kernel_size[1] * input_shape[-1] * output_elements\n",
        "            acti_flops = output_elements * acti_flops_map.get(acti_name, 0)\n",
        "\n",
        "        else:\n",
        "            param = 0\n",
        "            flops = 0\n",
        "\n",
        "        totparam += param\n",
        "        totflops += flops + acti_flops\n",
        "\n",
        "    return totparam, totflops\n"
      ],
      "metadata": {
        "id": "8gf5BX_KwA4V"
      },
      "id": "8gf5BX_KwA4V",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxXtxKHWtl8P",
        "outputId": "ad685808-66fd-40f3-c509-b5d99ccad97d"
      },
      "id": "LxXtxKHWtl8P",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(121930, 5085500)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07efdcc1-e0dc-493a-9a6a-e76c2e6b4920",
      "metadata": {
        "id": "07efdcc1-e0dc-493a-9a6a-e76c2e6b4920"
      },
      "source": [
        "# Question-4\n",
        "Write a Python code to build CNN using Keras and compute a  number of parameters,memory and FLOPs for the following model.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"3.jpg\" width=\"900\" height=\"700\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "297ed5e3-c963-43c6-a6ea-063fffe67231",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "297ed5e3-c963-43c6-a6ea-063fffe67231",
        "outputId": "0f0f904f-24e8-456f-97f1-bf5da41b0f5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 15, 15, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 6, 6, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2304)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 64)                147520    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 167562 (654.54 KB)\n",
            "Trainable params: 167562 (654.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    MaxPooling2D((2, 2),strides=2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2),strides=2),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_size = get_model_size(model)\n",
        "print(f\"Model size: {model_size / (1024 ** 2):.2f} MB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyxE8PEVxXNi",
        "outputId": "69db625f-a8d6-4217-93c4-d04ddf390a54"
      },
      "id": "TyxE8PEVxXNi",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model size: 0.64 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compute(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9LWw2DRxX7m",
        "outputId": "03ea3590-96f1-487c-ce4c-42a46342adb9"
      },
      "id": "C9LWw2DRxX7m",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(167562, 8121148)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81bd615b-8d3f-40a3-b174-e2879460c4c3",
      "metadata": {
        "id": "81bd615b-8d3f-40a3-b174-e2879460c4c3"
      },
      "source": [
        "## Output Shape of 3DCNN\n",
        "\n",
        "<img src=\"13.png\" width=\"400\" height=\"300\">\n",
        "<img src=\"14.png\" width=\"400\" height=\"300\">\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### 3DCNN parameters calculations\n",
        "<img src=\"7.png\" width=\"900\" height=\"700\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c329993c-6a36-493f-9e05-b4ee86005753",
      "metadata": {
        "id": "c329993c-6a36-493f-9e05-b4ee86005753"
      },
      "source": [
        "### 3DCNN FLOPs calculations\n",
        "\n",
        "<img src=\"8.png\" width=\"900\" height=\"700\">\n",
        "\n",
        "\n",
        "\n",
        "### 3DCNN FLOPs calculation for Pooling Layers\n",
        "<img src=\"15.png\" width=\"900\" height=\"700\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57e700ae-b194-434f-826c-1e8183acc37e",
      "metadata": {
        "id": "57e700ae-b194-434f-826c-1e8183acc37e"
      },
      "source": [
        "# Question-5\n",
        "\n",
        "You are tasked with designing a 3D Convolutional Neural Network (3D CNN) to classify video clips into one of five categories, such as walking, running, jumping, swimming, and cycling. Each video clip consists of 16 frames of size 64x64, and the data has a single channel (grayscale). The model should include two 3D convolutional layers followed by max-pooling layers, a flattening layer, and fully connected dense layers. Specifically, the architecture should satisfy the following requirements:\n",
        "\n",
        "The input layer should accept a shape of (16, 64, 64, 1) corresponding to the temporal, height, width, and channel dimensions.\n",
        "The first 3D convolutional layer should have 32 filters of size (3, 3, 3) and use ReLU activation.\n",
        "The first max-pooling layer should have a pool size of (2, 2, 2) to downsample the feature maps.\n",
        "The second 3D convolutional layer should have 64 filters of size (3, 3, 3) and use ReLU activation.\n",
        "The second max-pooling layer should again have a pool size of (2, 2, 2).\n",
        "The flattened layer should connect to a dense layer with 128 neurons using ReLU activation, followed by the output layer with 5 neurons and a softmax activation.\n",
        "Design and implement this 3D CNN architecture, compute the number of parameters for each layer, compute the model size and compute the FLOPs.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "6dee948f-5288-4fbc-b995-443a3d975263",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dee948f-5288-4fbc-b995-443a3d975263",
        "outputId": "286cc4e9-a44a-4f4c-8c3b-17e9c6c86c75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d (Conv3D)             (None, 14, 62, 62, 32)    896       \n",
            "                                                                 \n",
            " max_pooling3d (MaxPooling3  (None, 7, 31, 31, 32)     0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv3d_1 (Conv3D)           (None, 5, 29, 29, 64)     55360     \n",
            "                                                                 \n",
            " max_pooling3d_1 (MaxPoolin  (None, 2, 14, 14, 64)     0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               3211392   \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3268293 (12.47 MB)\n",
            "Trainable params: 3268293 (12.47 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "### Write  your code here\n",
        "model = Sequential([\n",
        "    Conv3D(32, (3, 3, 3), activation='relu', input_shape=(16, 64, 64, 1)),\n",
        "    MaxPooling3D((2, 2, 2)),\n",
        "    Conv3D(64, (3, 3, 3), activation='relu'),\n",
        "    MaxPooling3D((2, 2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute(model):\n",
        "    totparam = 0\n",
        "    totflops = 0\n",
        "\n",
        "    acti_flops_map = {\n",
        "        \"relu\": 1,\n",
        "        \"sigmoid\": 1,\n",
        "        \"tanh\": 1,\n",
        "        \"softmax\": 6,\n",
        "    }\n",
        "\n",
        "    for layer in model.layers:\n",
        "        layertype = layer.__class__.__name__\n",
        "        acti_flops = 0\n",
        "        acti = getattr(layer, \"activation\", None)\n",
        "        acti_name = acti.__name__ if acti else None\n",
        "\n",
        "        if layertype == \"Dense\":\n",
        "            inputunits = layer.input_shape[-1]\n",
        "            outputunits = layer.output_shape[-1]\n",
        "            param = inputunits * outputunits + outputunits\n",
        "            flops = 2 * outputunits * inputunits\n",
        "            acti_flops = outputunits * acti_flops_map.get(acti_name, 0)\n",
        "\n",
        "        elif layertype in [\"Conv2D\", \"Conv3D\"]:\n",
        "            kernel_size = layer.kernel_size\n",
        "            input_shape = layer.input_shape\n",
        "            output_shape = layer.output_shape\n",
        "            filters = layer.filters\n",
        "\n",
        "            if layertype == \"Conv2D\":\n",
        "                param = (filters * kernel_size[0] * kernel_size[1] *\n",
        "                         input_shape[-1]) + filters\n",
        "            elif layertype == \"Conv3D\":\n",
        "                param = (filters * kernel_size[0] * kernel_size[1] *\n",
        "                         kernel_size[2] * input_shape[-1]) + filters\n",
        "\n",
        "            output_elements = (\n",
        "                output_shape[1] * output_shape[2] * output_shape[3] * filters\n",
        "                if layertype == \"Conv3D\"\n",
        "                else output_shape[1] * output_shape[2] * filters\n",
        "            )\n",
        "\n",
        "            flops = (\n",
        "                2 * kernel_size[0] * kernel_size[1] *\n",
        "                (kernel_size[2] if layertype == \"Conv3D\" else 1) *\n",
        "                input_shape[-1] * output_elements\n",
        "            )\n",
        "            acti_flops = output_elements * acti_flops_map.get(acti_name, 0)\n",
        "\n",
        "        else:\n",
        "            param = 0\n",
        "            flops = 0\n",
        "\n",
        "        totparam += param\n",
        "        totflops += flops + acti_flops\n",
        "\n",
        "    return totparam, totflops\n"
      ],
      "metadata": {
        "id": "wKpfYwpuzrrV"
      },
      "id": "wKpfYwpuzrrV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_size = get_model_size(model)\n",
        "print(f\"Model size: {model_size / (1024 ** 2):.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaNNYGt1zFrF",
        "outputId": "85a840a7-0c11-4145-9cdb-1abd9ee2962f"
      },
      "id": "EaNNYGt1zFrF",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model size: 12.47 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compute(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yi7gi_x2zW2g",
        "outputId": "538c2882-5c5a-4f82-8fde-2a098fbc344d"
      },
      "id": "yi7gi_x2zW2g",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3230853, 12306270)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0457d1f-bca5-405f-8dd3-2fbc26dd7038",
      "metadata": {
        "id": "d0457d1f-bca5-405f-8dd3-2fbc26dd7038"
      },
      "source": [
        "# Question-6\n",
        "\n",
        "A company is building a system to predict customer sentiment (positive or negative) based on a sequence of customer reviews.\n",
        "Each review is represented as a feature vector of size 4, where each feature corresponds to a specific aspect of the review, such as tone, length, and keyword presence. To process this sequential data, the team decides to use a Recurrent Neural Network (RNN).\n",
        "\n",
        "The input size n<sub>x</sub> is 4, meaning each input vector x<sup>t</sup> has 4 features.  \n",
        "The hidden layer has 3 hidden units n<sub>a</sub>=3.  \n",
        "The output size n<sub>y</sub> is 2, corresponding to the two possible sentiment classes (positive or negative).  \n",
        "The sequence length T<sub>x</sub> is 5, meaning the RNN will process a sequence of 5 reviews at a time.\n",
        "use sigmoid activation functions in the output layers and compute the number of parameters and memory in the RNN model.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"9.png\" width=\"300\" height=\"100\">\n",
        "\n",
        "\n",
        "Number of parameter of RNN = g × [a(a+i) + a]\n",
        "\n",
        "a --> hidden unit\n",
        "\n",
        "i ---> input unit\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "e77c1ac0-6a30-46c5-93d8-e78f34284ae6",
      "metadata": {
        "id": "e77c1ac0-6a30-46c5-93d8-e78f34284ae6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9afe4044-2865-4131-8086-0ddd21f5f21d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_1 (SimpleRNN)    (None, 3)                 24        \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 2)                 8         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32 (128.00 Byte)\n",
            "Trainable params: 32 (128.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.engine.sequential.Sequential at 0x7bbabce8bd50>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "from keras.layers import Dense, SimpleRNN\n",
        "\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(3, input_shape=(5,4), activation='sigmoid'))\n",
        "model.add(Dense(units=2, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute(model):\n",
        "    totparam = 0\n",
        "    totflops = 0\n",
        "\n",
        "    acti_flops_map = {\n",
        "        \"relu\": 1,\n",
        "        \"sigmoid\": 1,\n",
        "        \"tanh\": 1,\n",
        "        \"softmax\": 6,\n",
        "    }\n",
        "\n",
        "    for layer in model.layers:\n",
        "        layertype = layer.__class__.__name__\n",
        "        acti_flops = 0\n",
        "        acti = getattr(layer, \"activation\", None)\n",
        "        acti_name = acti.__name__ if acti else None\n",
        "\n",
        "        if layertype == \"Dense\":\n",
        "            inputunits = layer.input_shape[-1]\n",
        "            outputunits = layer.output_shape[-1]\n",
        "            param = inputunits * outputunits + outputunits\n",
        "            flops = 2 * outputunits * inputunits\n",
        "            acti_flops = outputunits * acti_flops_map.get(acti_name, 0)\n",
        "\n",
        "        elif layertype == \"SimpleRNN\":\n",
        "            inputunits = layer.input_shape[-1]\n",
        "            hiddenunits = layer.units\n",
        "            param = hiddenunits * (hiddenunits + inputunits + 1)\n",
        "            flops = 2 * hiddenunits * (hiddenunits + inputunits)\n",
        "            acti_flops = hiddenunits * acti_flops_map.get(acti_name, 0)\n",
        "\n",
        "        else:\n",
        "            param = 0\n",
        "            flops = 0\n",
        "\n",
        "        totparam += param\n",
        "        totflops += flops + acti_flops\n",
        "\n",
        "    return totparam, totflops\n"
      ],
      "metadata": {
        "id": "x0PxBJQYF6jd"
      },
      "id": "x0PxBJQYF6jd",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_size = get_model_size(model)"
      ],
      "metadata": {
        "id": "5l_kJXeFp6KD"
      },
      "id": "5l_kJXeFp6KD",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ei6wTS3cqKFf",
        "outputId": "025058f1-4d8d-4774-edf8-d09cb7ed4b23"
      },
      "id": "ei6wTS3cqKFf",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 59)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1933955e-5b05-4e2e-9b36-27b5190fea54",
      "metadata": {
        "id": "1933955e-5b05-4e2e-9b36-27b5190fea54"
      },
      "source": [
        "# Question 7\n",
        "\n",
        "Write a Python code to implement a single LSTM unit for the follwoing and compute the parameter of the follwoing model using Keras.\n",
        "    \n",
        "<img src=\"https://github.com/kmkarakaya/ML_tutorials/blob/master/images/LSTM_internal2.png?raw=true\" width=\"500\">\n",
        "\n",
        "\n",
        " Notice that we can guess the size (shape) of W,U and b given:\n",
        " * Input size ($h_{t-1}$ and $x_{t}$ )\n",
        " * Output size ($h_{t-1}$)\n",
        "\n",
        " Since output must equal to Hidden State (hx1) size:\n",
        "\n",
        "  * for W param =  ($h$ × $x$)\n",
        "  * for U param =  ($h$ × $h$)\n",
        "  * for Biases  param =   $h$\n",
        "\n",
        " * total params = W param + U param + Biases param\n",
        "  \n",
        "    =  ($h$ × $x$) +  ($h$ × $h$) +  $h$\n",
        "\n",
        "    =  ( ($h$ × $x$) +  ($h$ × $h$) +   $h$ )\n",
        "\n",
        "    =  ( ($x$ + $h$) ×  $h$  +   $h$ )\n",
        "\n",
        "* there are 4 functions which are exactly defined in the same way, in the LSTM layer, there will be\n",
        "\n",
        " ##   **LSTM parameter number = 4 × (($x$ + $h$) × $h$ +$h$)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "32110225-3e3a-482c-a850-835920d0fda8",
      "metadata": {
        "id": "32110225-3e3a-482c-a850-835920d0fda8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af004de3-1ab1-4ca2-eebe-cc3cb53aca1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 3)                 96        \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 100 (400.00 Byte)\n",
            "Trainable params: 100 (400.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "### Write  your code here\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "input_size = 4\n",
        "hidden_size = 3\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(hidden_size, input_shape=(None, input_size)),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_model_size(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbZtH8wKq1uE",
        "outputId": "17e582a1-d244-4a91-8f8f-72e21699ae7c"
      },
      "id": "gbZtH8wKq1uE",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute(model):\n",
        "    totparam = 0\n",
        "    totflops = 0\n",
        "\n",
        "    acti_flops_map = {\n",
        "        \"relu\": 1,\n",
        "        \"sigmoid\": 1,\n",
        "        \"tanh\": 1,\n",
        "        \"softmax\": 6,\n",
        "    }\n",
        "\n",
        "    for layer in model.layers:\n",
        "        layertype = layer.__class__.__name__\n",
        "        acti_flops = 0\n",
        "        acti = getattr(layer, \"activation\", None)\n",
        "        acti_name = acti.__name__ if acti else None\n",
        "\n",
        "        if layertype == \"Dense\":\n",
        "            inputunits = layer.input_shape[-1]\n",
        "            outputunits = layer.output_shape[-1]\n",
        "            param = inputunits * outputunits + outputunits\n",
        "            flops = 2 * outputunits * inputunits\n",
        "            acti_flops = outputunits * acti_flops_map.get(acti_name, 0)\n",
        "\n",
        "        elif layertype == \"SimpleRNN\":\n",
        "            inputunits = layer.input_shape[-1]\n",
        "            hiddenunits = layer.units\n",
        "            param = hiddenunits * (hiddenunits + inputunits + 1)\n",
        "            flops = 2 * hiddenunits * (hiddenunits + inputunits)\n",
        "            acti_flops = hiddenunits * acti_flops_map.get(acti_name, 0)\n",
        "\n",
        "        elif layertype == \"LSTM\":\n",
        "            inputunits = layer.input_shape[-1]\n",
        "            hiddenunits = layer.units\n",
        "            param = 4 * (hiddenunits * (inputunits + hiddenunits + 1))\n",
        "            flops = 4 * (2 * hiddenunits * (inputunits + hiddenunits))\n",
        "            acti_flops = 4 * hiddenunits * acti_flops_map.get(acti_name, 0)\n",
        "\n",
        "        else:\n",
        "            param = 0\n",
        "            flops = 0\n",
        "\n",
        "        totparam += param\n",
        "        totflops += flops + acti_flops\n",
        "\n",
        "    return totparam, totflops"
      ],
      "metadata": {
        "id": "lq3DZfT1q-kl"
      },
      "id": "lq3DZfT1q-kl",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cLPpfjerDSc",
        "outputId": "3b27dda4-fed1-45f0-8b17-a46450b7c050"
      },
      "id": "8cLPpfjerDSc",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 187)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D75S75TkrYAh"
      },
      "id": "D75S75TkrYAh",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}